{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f211ab9",
   "metadata": {},
   "source": [
    "Stratégie “méta” : partir d’une allocation low-vol et essayer de détecter des jours “spéciaux” (risk-on / risk-off) à partir de features de marché. La différence ici, c’est qu’au lieu d’une régression logistique, on utilise un modèle XGBoost (plus flexible) pour estimer deux probabilités : risque de forte baisse (queue basse) et chance de forte hausse (queue haute). Ensuite, sur la fenêtre de test (365 derniers jours), on transforme ces probabilités en régimes d’allocation (baseline low-vol, equal-weight ou cash) et on backteste la perf nette en incluant des coûts via le turnover, puis on compare au baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2731341",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# params\n",
    "Q_MOVE = 0.30\n",
    "TEST_DAYS = 365\n",
    "COST_BPS = 10\n",
    "\n",
    "# features stack (reprend rets/close/vol déjà calculés plus haut)\n",
    "# si tu lances cellule B seule: rebuild rets/close/vol comme avant\n",
    "\n",
    "WIN_MOM1, WIN_MOM2, WIN_MOM3 = 5, 20, 60\n",
    "LAM = 0.94\n",
    "WIN_VOL = 20\n",
    "\n",
    "vol_ewma = np.sqrt((rets**2).ewm(alpha=1-LAM).mean())\n",
    "vol_roll = rets.rolling(WIN_VOL).std()\n",
    "mom5  = close.pct_change(WIN_MOM1)\n",
    "mom20 = close.pct_change(WIN_MOM2)\n",
    "mom60 = close.pct_change(WIN_MOM3)\n",
    "\n",
    "# dataset long format\n",
    "X = pd.concat([\n",
    "    rets.stack().rename(\"ret_1\"),\n",
    "    mom5.stack().rename(\"ret_5\"),\n",
    "    mom20.stack().rename(\"ret_20\"),\n",
    "    mom60.stack().rename(\"ret_60\"),\n",
    "    vol_ewma.stack().rename(\"vol_ewma\"),\n",
    "    vol_roll.stack().rename(\"vol_roll20\"),\n",
    "    (vol_ewma / vol_ewma.rolling(252).mean()).stack().rename(\"vol_ratio\"),\n",
    "], axis=1).dropna()\n",
    "\n",
    "fut = rets.shift(-1).stack().rename(\"ret_fut\")\n",
    "df_all = pd.concat([X, fut], axis=1).dropna()\n",
    "\n",
    "down_thr = df_all[\"ret_fut\"].quantile(Q_MOVE)\n",
    "up_thr   = df_all[\"ret_fut\"].quantile(1 - Q_MOVE)\n",
    "\n",
    "df_all[\"y_down\"] = (df_all[\"ret_fut\"] <= down_thr).astype(int)\n",
    "df_all[\"y_up\"]   = (df_all[\"ret_fut\"] >= up_thr).astype(int)\n",
    "\n",
    "cutoff = df_all.index.get_level_values(0).max() - pd.Timedelta(days=TEST_DAYS)\n",
    "train = df_all[df_all.index.get_level_values(0) < cutoff].copy()\n",
    "test  = df_all[df_all.index.get_level_values(0) >= cutoff].copy()\n",
    "\n",
    "X_train = train.drop(columns=[\"ret_fut\",\"y_down\",\"y_up\"])\n",
    "X_test  = test.drop(columns=[\"ret_fut\",\"y_down\",\"y_up\"])\n",
    "y_down_train = train[\"y_down\"]\n",
    "y_up_train   = train[\"y_up\"]\n",
    "y_down_test  = test[\"y_down\"]\n",
    "y_up_test    = test[\"y_up\"]\n",
    "\n",
    "# model params (safe)\n",
    "params = dict(\n",
    "    n_estimators=400,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    min_child_weight=5,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "m_down = XGBClassifier(**params)\n",
    "m_up   = XGBClassifier(**params)\n",
    "\n",
    "m_down.fit(X_train, y_down_train)\n",
    "m_up.fit(X_train, y_up_train)\n",
    "\n",
    "# proba\n",
    "train_pdown = m_down.predict_proba(X_train)[:, 1]\n",
    "train_pup   = m_up.predict_proba(X_train)[:, 1]\n",
    "test[\"p_down\"] = m_down.predict_proba(X_test)[:, 1]\n",
    "test[\"p_up\"]   = m_up.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# threshold calibration (train)\n",
    "# top tail -> act only on high confidence\n",
    "THR_DOWN = float(np.quantile(train_pdown, 0.95))\n",
    "THR_UP   = float(np.quantile(train_pup,   0.95))\n",
    "print(\"thr_down\", THR_DOWN, \"thr_up\", THR_UP)\n",
    "\n",
    "# meta mode per row\n",
    "test[\"mode\"] = \"baseline\"\n",
    "test.loc[test[\"p_down\"] >= THR_DOWN, \"mode\"] = \"risk_off\"\n",
    "test.loc[(test[\"mode\"] == \"baseline\") & (test[\"p_up\"] >= THR_UP), \"mode\"] = \"risk_on\"\n",
    "\n",
    "# mode by date (mean)\n",
    "mode_by_date = (\n",
    "    test.reset_index()\n",
    "        .groupby(\"timestamp\")[[\"p_down\",\"p_up\",\"mode\"]]\n",
    "        .agg({\"p_down\":\"mean\",\"p_up\":\"mean\",\"mode\":lambda x: x.iloc[0]})\n",
    ")\n",
    "\n",
    "dates_test = mode_by_date.index\n",
    "\n",
    "# weights templates\n",
    "# baseline = low_vol\n",
    "w_low = (vol_roll.le(vol_roll.quantile(0.5, axis=1), axis=0)).astype(float)\n",
    "w_low = w_low.reindex(dates_test).fillna(0.0)\n",
    "\n",
    "# risk_on = equal weight\n",
    "w_on = pd.DataFrame(1.0, index=dates_test, columns=SYMBOLS)\n",
    "\n",
    "# risk_off = cash\n",
    "w_off = pd.DataFrame(0.0, index=dates_test, columns=SYMBOLS)\n",
    "\n",
    "# build W\n",
    "W = pd.DataFrame(index=dates_test, columns=SYMBOLS, dtype=float)\n",
    "for d in dates_test:\n",
    "    m = mode_by_date.loc[d, \"mode\"]\n",
    "    if m == \"risk_off\":\n",
    "        W.loc[d] = w_off.loc[d]\n",
    "    elif m == \"risk_on\":\n",
    "        W.loc[d] = w_on.loc[d]\n",
    "    else:\n",
    "        W.loc[d] = w_low.loc[d]\n",
    "\n",
    "W = W.clip(lower=0.0)\n",
    "W = W.div(W.sum(axis=1).replace(0, np.nan), axis=0).fillna(0.0)\n",
    "\n",
    "# backtest test window\n",
    "rets_test = rets.reindex(dates_test)\n",
    "\n",
    "def run_bt(weights, rets, cost_bps=10):\n",
    "    w = weights.shift(1).reindex(rets.index).fillna(0.0)\n",
    "    w = w.div(w.sum(axis=1).replace(0, np.nan), axis=0).fillna(0.0)\n",
    "    gross = (w * rets).sum(axis=1)\n",
    "    to = w.diff().abs().sum(axis=1).fillna(0.0)\n",
    "    cost = to * (cost_bps / 10000.0)\n",
    "    net = gross - cost\n",
    "    return net, to\n",
    "\n",
    "def stats(r, freq=365):\n",
    "    r = r.dropna()\n",
    "    eq = (1 + r).cumprod()\n",
    "    mu = r.mean() * freq\n",
    "    sig = r.std() * np.sqrt(freq)\n",
    "    sharpe = mu / sig if sig > 0 else np.nan\n",
    "    dd = (eq / eq.cummax() - 1.0).min()\n",
    "    ann = eq.iloc[-1] ** (freq/len(r)) - 1 if len(r) > 0 else np.nan\n",
    "    return float(ann), float(sig), float(sharpe), float(dd)\n",
    "\n",
    "r_meta, to_meta = run_bt(W, rets_test, cost_bps=COST_BPS)\n",
    "r_base, to_base = run_bt(w_low, rets_test, cost_bps=COST_BPS)\n",
    "\n",
    "print(\"baseline test:\", stats(r_base), \"turn\", float(to_base.mean()))\n",
    "print(\"xgb meta test:\", stats(r_meta), \"turn\", float(to_meta.mean()))\n",
    "print(\"modes:\", mode_by_date[\"mode\"].value_counts().to_dict())\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot((1+r_base.fillna(0)).cumprod(), label=\"baseline low_vol\")\n",
    "plt.plot((1+r_meta.fillna(0)).cumprod(), label=\"xgb meta\")\n",
    "plt.legend()\n",
    "plt.title(\"Test equity\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e5fa8",
   "metadata": {},
   "source": [
    "thr_down 0.4721072018146515 thr_up 0.4820227026939392\n",
    "\n",
    "baseline test: (-0.27284050251585945, 0.5103395328575311, -0.36612463641141907, -0.4492806842792576) turn 0.07741347905282331\n",
    "\n",
    "xgb meta test: (-0.2934218385645678, 0.5112396706414283, -0.4206347012988575, -0.4492806842792576) turn 0.09198542805100182\n",
    "\n",
    "modes: {'baseline': 363, 'risk_on': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f572e6",
   "metadata": {},
   "source": [
    "![Image test 10](image/image_test_10.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1586bea5",
   "metadata": {},
   "source": [
    "Sur la période test, le baseline low-vol est négatif (Sharpe < 0), et la version XGBoost méta fait légèrement pire, avec un turnover un peu plus élevé. Le compteur des modes montre que le modèle reste quasiment tout le temps en baseline (363 jours) et déclenche très rarement un signal risk_on (3 jours), et jamais de risk_off. \n",
    "\n",
    "Cela veut dire que même avec un modèle plus puissant, le signal est soit trop “timide” (seuils élevés via quantile 95%), soit que les features actuelles ne donnent pas une séparation claire des gros mouvements exploitables. \n",
    "\n",
    "Résultat : on ajoute surtout de la complexité/turnover sans améliorer la perf sur cette fenêtre. Une suite logique serait de tester d’autres seuils (quantile 90% par ex) ou une autre définition des “queues” (ex : Q_MOVE = 0.10)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
