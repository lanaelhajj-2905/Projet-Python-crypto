{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e52e69",
   "metadata": {},
   "source": [
    "Dans cette partie, on calcule d’abord les rendements log (log-returns) à partir des prix de clôture.\n",
    "\n",
    "Ensuite, on construit plusieurs estimateurs de volatilité “classiques” (rolling, EWMA, Parkinson, Garman-Klass). \n",
    "\n",
    "Puis on estime une volatilité conditionnelle via des modèles ARCH/GARCH (GARCH, GJR-GARCH et EGARCH) avec deux choix de distribution (normale et Student-t). \n",
    "\n",
    "Enfin, on compare ces prédictions de volatilité à une volatilité réalisée (réalisée = écart-type des rendements sur un horizon futur) avec des métriques simples : MSE et corrélation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28ae12",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "\n",
    "# 0) params globaux\n",
    "WIN = 20\n",
    "LAM = 0.94\n",
    "ARCH_WINDOW = 750     # ~3 ans daily (a peu pres)\n",
    "HORIZONS = (5, 20)    # 1 semaine / 1 mois\n",
    "\n",
    "\n",
    "def add_returns(df):\n",
    "    # 1) returns log\n",
    "    df = df.copy()\n",
    "    df[\"ret\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_vol_simple(df):\n",
    "    # 2) vol simple (baseline)\n",
    "    # 2a) rolling std\n",
    "    df[\"vol_rolling_20\"] = df[\"ret\"].rolling(WIN).std()\n",
    "\n",
    "    # 2b) ewma\n",
    "    df[\"vol_ewma\"] = np.sqrt((df[\"ret\"] ** 2).ewm(alpha=1 - LAM).mean())\n",
    "\n",
    "    # 2c) parkinson (high/low)\n",
    "    hl = np.log(df[\"high\"] / df[\"low\"])\n",
    "    df[\"vol_parkinson\"] = np.sqrt((hl ** 2).rolling(WIN).mean() / (4 * np.log(2)))\n",
    "\n",
    "    # 2d) garman-klass (OHLC)\n",
    "    ho = np.log(df[\"high\"] / df[\"open\"])\n",
    "    lo = np.log(df[\"low\"] / df[\"open\"])\n",
    "    co = np.log(df[\"close\"] / df[\"open\"])\n",
    "    gk_var = 0.5 * (ho - lo) ** 2 - (2 * np.log(2) - 1) * (co ** 2)\n",
    "    df[\"vol_gk\"] = np.sqrt(gk_var.rolling(WIN).mean().clip(lower=0))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def arch_forecast_vol(ret, model=\"GARCH\", dist=\"normal\", window=ARCH_WINDOW):\n",
    "    # 3) garch forecast (walk-forward)\n",
    "    # 3a) % scale (arch prefere %)\n",
    "    r = (ret.dropna() * 100.0).copy()\n",
    "    vol = pd.Series(index=r.index, dtype=float)\n",
    "\n",
    "    # 3b) garde fou (pas assez de data)\n",
    "    if len(r) <= window + 10:\n",
    "        return vol\n",
    "\n",
    "    # 3c) boucle expanding window\n",
    "    for i in range(window, len(r)):\n",
    "        sub = r.iloc[:i]\n",
    "\n",
    "        # 3d) choix modele\n",
    "        if model == \"GARCH\":\n",
    "            am = arch_model(sub, vol=\"Garch\", p=1, q=1, dist=dist)\n",
    "        elif model == \"GJR\":\n",
    "            am = arch_model(sub, vol=\"Garch\", p=1, o=1, q=1, dist=dist)\n",
    "        elif model == \"EGARCH\":\n",
    "            am = arch_model(sub, vol=\"EGarch\", p=1, q=1, dist=dist)\n",
    "        else:\n",
    "            raise ValueError(\"bad model\")\n",
    "\n",
    "        # 3e) fit + forecast 1 pas\n",
    "        res = am.fit(disp=\"off\")\n",
    "        f = res.forecast(horizon=1)\n",
    "\n",
    "        # 3f) back scale (% -> decimal)\n",
    "        vol.iloc[i] = np.sqrt(f.variance.values[-1, 0]) / 100.0\n",
    "\n",
    "    return vol\n",
    "\n",
    "\n",
    "def add_vol_arch(df):\n",
    "    # 4) vol arch/garch\n",
    "    df[\"vol_garch_n\"]  = arch_forecast_vol(df[\"ret\"], \"GARCH\", \"normal\")\n",
    "    df[\"vol_gjr_n\"]    = arch_forecast_vol(df[\"ret\"], \"GJR\",   \"normal\")\n",
    "    df[\"vol_egarch_n\"] = arch_forecast_vol(df[\"ret\"], \"EGARCH\",\"normal\")\n",
    "\n",
    "    df[\"vol_garch_t\"]  = arch_forecast_vol(df[\"ret\"], \"GARCH\", \"t\")\n",
    "    df[\"vol_gjr_t\"]    = arch_forecast_vol(df[\"ret\"], \"GJR\",   \"t\")\n",
    "    df[\"vol_egarch_t\"] = arch_forecast_vol(df[\"ret\"], \"EGARCH\",\"t\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def bench(df, symbol):\n",
    "    # 5) benchmark pred vol vs realized vol\n",
    "    rows = []\n",
    "\n",
    "    for h in HORIZONS:\n",
    "        # 5a) realized vol (future) = std sur h jours, shift -1\n",
    "        rv = df[\"ret\"].rolling(h).std().shift(-1).rename(\"rv\")\n",
    "\n",
    "        # 5b) liste modeles vol\n",
    "        for col in [\n",
    "            \"vol_rolling_20\", \"vol_ewma\", \"vol_parkinson\", \"vol_gk\",\n",
    "            \"vol_garch_n\", \"vol_gjr_n\", \"vol_egarch_n\",\n",
    "            \"vol_garch_t\", \"vol_gjr_t\", \"vol_egarch_t\",\n",
    "        ]:\n",
    "            tmp = pd.concat([df[col].rename(\"pred\"), rv], axis=1).dropna()\n",
    "\n",
    "            # 5c) mini taille sample\n",
    "            if len(tmp) < 250:\n",
    "                continue\n",
    "\n",
    "            # 5d) metriques\n",
    "            mse = float(np.mean((tmp[\"pred\"] - tmp[\"rv\"]) ** 2))\n",
    "            corr = float(tmp[\"pred\"].corr(tmp[\"rv\"]))\n",
    "\n",
    "            rows.append({\n",
    "                \"symbol\": symbol,\n",
    "                \"h\": h,\n",
    "                \"model\": col,\n",
    "                \"mse\": mse,\n",
    "                \"corr\": corr,\n",
    "                \"n\": len(tmp)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# 6) run sur tout l'univers\n",
    "results = []\n",
    "\n",
    "for sym, df0 in all_data.items():\n",
    "    print(\"bench\", sym)\n",
    "\n",
    "    # 6a) returns + vol simple\n",
    "    df = add_returns(df0)\n",
    "    df = add_vol_simple(df)\n",
    "\n",
    "    # 6b) garch / arch (lourd)\n",
    "    print(\"arch\", sym)\n",
    "    df = add_vol_arch(df)\n",
    "\n",
    "    # 6c) bench final\n",
    "    df = df.dropna(subset=[\"ret\"])\n",
    "    res = bench(df, sym)\n",
    "\n",
    "    if not res.empty:\n",
    "        results.append(res)\n",
    "\n",
    "# 7) concat + output csv\n",
    "results_df = pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n",
    "\n",
    "if results_df.empty:\n",
    "    print(\"no results\")\n",
    "else:\n",
    "    results_df = results_df.sort_values([\"h\", \"symbol\", \"mse\"])\n",
    "\n",
    "    print(\"\\n=== best per symbol / horizon ===\")\n",
    "    print(results_df.groupby([\"symbol\", \"h\"]).head(3))\n",
    "\n",
    "    results_df.to_csv(\"vol_benchmark_2021_2025_binance_public.csv\", index=False)\n",
    "    print(\"\\nsaved vol_benchmark_2021_2025_binance_public.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf60415",
   "metadata": {},
   "source": [
    "bench BTCUSDT\n",
    "arch BTCUSDT\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "/tmp/ipython-input-1472060719.py:66: ConvergenceWarning: The optimizer returned code 9. The message is:\n",
    "Iteration limit reached\n",
    "See scipy.optimize.fmin_slsqp for code meaning.\n",
    "\n",
    "  res = am.fit(disp=\"off\")\n",
    "bench ETHUSDT\n",
    "arch ETHUSDT\n",
    "bench BNBUSDT\n",
    "arch BNBUSDT\n",
    "bench SOLUSDT\n",
    "arch SOLUSDT\n",
    "bench XRPUSDT\n",
    "arch XRPUSDT\n",
    "bench PENGUUSDT\n",
    "arch PENGUUSDT\n",
    "\n",
    "=== best per symbol / horizon ===\n",
    "\n",
    "        symbol   h           model       mse      corr     n\n",
    "\n",
    "44     BNBUSDT   5     vol_garch_n  0.000139  0.714936  1074\n",
    "\n",
    "45     BNBUSDT   5       vol_gjr_n  0.000139  0.715667  1074\n",
    "\n",
    "46     BNBUSDT   5    vol_egarch_n  0.000142  0.699800  1074\n",
    "\n",
    "6      BTCUSDT   5    vol_egarch_n  0.000117  0.609112  1074\n",
    "\n",
    "4      BTCUSDT   5     vol_garch_n  0.000118  0.575491  1074\n",
    "\n",
    "5      BTCUSDT   5       vol_gjr_n  0.000119  0.514045  1074\n",
    "\n",
    "26     ETHUSDT   5    vol_egarch_n  0.000216  0.540083  1074\n",
    "\n",
    "24     ETHUSDT   5     vol_garch_n  0.000220  0.543532  1074\n",
    "\n",
    "25     ETHUSDT   5       vol_gjr_n  0.000221  0.545699  1074\n",
    "\n",
    "101  PENGUUSDT   5        vol_ewma  0.000755  0.553713   375\n",
    "\n",
    "100  PENGUUSDT   5  vol_rolling_20  0.000841  0.414695   359\n",
    "\n",
    "102  PENGUUSDT   5   vol_parkinson  0.003080  0.108505   360\n",
    "\n",
    "67     SOLUSDT   5     vol_garch_t  0.000339  0.690644  1074\n",
    "\n",
    "68     SOLUSDT   5       vol_gjr_t  0.000341  0.685763  1074\n",
    "\n",
    "64     SOLUSDT   5     vol_garch_n  0.000343  0.714909  1074\n",
    "\n",
    "88     XRPUSDT   5       vol_gjr_t  0.000533  0.712795  1074\n",
    "\n",
    "87     XRPUSDT   5     vol_garch_t  0.000538  0.709706  1074\n",
    "\n",
    "84     XRPUSDT   5     vol_garch_n  0.000543  0.736638  1074\n",
    "\n",
    "50     BNBUSDT  20  vol_rolling_20  0.000012  0.989284  1805\n",
    "\n",
    "52     BNBUSDT  20   vol_parkinson  0.000039  0.973069  1806\n",
    "\n",
    "56     BNBUSDT  20    vol_egarch_n  0.000041  0.879787  1074\n",
    "\n",
    "10     BTCUSDT  20  vol_rolling_20  0.000005  0.981309  1805\n",
    "\n",
    "11     BTCUSDT  20        vol_ewma  0.000014  0.946722  1806\n",
    "\n",
    "18     BTCUSDT  20       vol_gjr_t  0.000024  0.824239  1074\n",
    "\n",
    "30     ETHUSDT  20  vol_rolling_20  0.000009  0.982145  1805\n",
    "\n",
    "31     ETHUSDT  20        vol_ewma  0.000033  0.938120  1806\n",
    "\n",
    "34     ETHUSDT  20     vol_garch_n  0.000039  0.874174  1074\n",
    "\n",
    "104  PENGUUSDT  20  vol_rolling_20  0.000030  0.951676   359\n",
    "\n",
    "105  PENGUUSDT  20        vol_ewma  0.000079  0.880743   360\n",
    "\n",
    "106  PENGUUSDT  20   vol_parkinson  0.001799  0.472589   360\n",
    "\n",
    "70     SOLUSDT  20  vol_rolling_20  0.000021  0.982458  1805\n",
    "\n",
    "71     SOLUSDT  20        vol_ewma  0.000082  0.933336  1806\n",
    "\n",
    "72     SOLUSDT  20   vol_parkinson  0.000100  0.946799  1806\n",
    "\n",
    "90     XRPUSDT  20  vol_rolling_20  0.000032  0.977433  1805\n",
    "\n",
    "91     XRPUSDT  20        vol_ewma  0.000099  0.929760  1806\n",
    "\n",
    "92     XRPUSDT  20   vol_parkinson  0.000197  0.897891  1806\n",
    "\n",
    "saved vol_benchmark_2021_2025_binance_public.csv\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
